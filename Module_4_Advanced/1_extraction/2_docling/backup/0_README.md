## ðŸ“š Table of Contents

1. [What is Docling?](#what-is-docling)
2. [The Document Processing Problem](#the-document-processing-problem)
3. [How Docling Works](#how-docling-works)
4. [Models & Libraries Behind the Scenes](#models--libraries-behind-the-scenes)
5. [What Can Docling Do?](#what-can-docling-do)
6. [Introduction to OCR](#introduction-to-ocr)
7. [Alternatives to Docling](#alternatives-to-docling)
8. [Comparison: Open Source vs Paid vs Cloud](#comparison-open-source-vs-paid-vs-cloud)
9. [When to Use What](#when-to-use-what)
10. [Getting Started](#getting-started)

---

## What is Docling?

### Definition

**Docling** is an open-source document understanding library that converts complex documents (PDFs, DOCX, PPTX, images) into structured, machine-readable data using AI models.

**Created by:** IBM Research - Data Science for Scientific Discovery (DS4SD)  
**Released:** 2024  
**License:** Apache 2.0 (Free, Open Source)  
**Repository:** https://github.com/DS4SD/docling  
**Language:** Python  

### Simple Explanation

```
Traditional PDF tools:  Read text from PDF (like copy-paste)
Docling:               Understand document structure using AI
```

**Example:**
```
Input:  Research paper PDF
        - Multi-column layout
        - Complex tables
        - LaTeX diagrams
        - Mathematical equations

Traditional tool output:
        Scrambled text âŒ
        Broken tables âŒ
        Missing figures âŒ

Docling output:
        âœ… Text in correct reading order
        âœ… Tables as perfect CSV files
        âœ… Figures rendered as images
        âœ… Structure preserved (headers, sections)
```

### Why It Exists

**Problem:** PDFs are designed for humans, not machines

```
PDF = Portable Document Format
â†“
Designed for: Printing and viewing
NOT designed for: Data extraction
```

**What PDFs contain:**
- Text positioning (x, y coordinates)
- Font information
- Graphics paths
- Images
- NO semantic structure (no "this is a table" tag)

**Docling's solution:** Use AI to understand document structure

---

## The Document Processing Problem

### Challenge 1: Layout Understanding

**Problem:**
```
PDF internally:
Text at (100, 200): "Introduction"
Text at (100, 250): "Methods"
Text at (300, 200): "Abstract"
Text at (300, 250): "Results"

Reading left-to-right, top-to-bottom:
"Introduction", "Abstract", "Methods", "Results" âŒ WRONG ORDER!

Correct reading (two columns):
Column 1: "Introduction", "Methods"
Column 2: "Abstract", "Results"
```

**Docling solution:** AI model understands layout, preserves correct order âœ…

### Challenge 2: Table Extraction

**Problem:**
```
PDF sees:
Text at (100, 300): "Model"
Text at (200, 300): "Params"
Text at (300, 300): "BLEU"
Text at (100, 320): "Base"
Text at (200, 320): "65M"
...

Is this a table? Where are cell boundaries?
Traditional tools: Guess using whitespace âŒ
```

**Docling solution:** AI model understands table structure âœ…
```
Output:
Model,Params,BLEU
Base,65M,27.3
Big,213M,28.4
```

### Challenge 3: Vector Graphics

**Problem:**
```
PDF contains:
- Path objects (lines, curves)
- Drawing commands
- NOT embedded images

Traditional tools:
"No images found" âŒ

Actual content:
LaTeX/TikZ diagrams, matplotlib charts
```

**Docling solution:** Renders PDF region as image âœ…

### Challenge 4: Scanned Documents

**Problem:**
```
Scanned PDF = Photo of document
No text layer, just pixels

Traditional tools:
Extract nothing âŒ
```

**Docling solution:** OCR (Optical Character Recognition) âœ…

---

## How Docling Works

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT LAYER                              â”‚
â”‚  Supported formats: PDF, DOCX, PPTX, HTML, Images          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 DOCUMENT CONVERTER                          â”‚
â”‚                                                             â”‚
â”‚  Detects format â†’ Routes to appropriate pipeline           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PDF PIPELINE                               â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Step 1: PDF Parser (PyPDFium2)                      â”‚  â”‚
â”‚  â”‚  â€¢ Renders pages as images (72-288 DPI)             â”‚  â”‚
â”‚  â”‚  â€¢ Extracts embedded resources                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Step 2: Layout Analysis (AI)                        â”‚  â”‚
â”‚  â”‚  â€¢ Model: Layout-Heron (Vision Transformer)         â”‚  â”‚
â”‚  â”‚  â€¢ Identifies: text, tables, figures, captions      â”‚  â”‚
â”‚  â”‚  â€¢ Creates bounding boxes                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Step 3: OCR (if needed)                            â”‚  â”‚
â”‚  â”‚  â€¢ Detects if page is scanned                       â”‚  â”‚
â”‚  â”‚  â€¢ Runs OCR engine                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Step 4: Specialized Processing                      â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Tables:                                             â”‚  â”‚
â”‚  â”‚  â€¢ TableFormer AI model                             â”‚  â”‚
â”‚  â”‚  â€¢ Parses cell structure                            â”‚  â”‚
â”‚  â”‚  â€¢ Outputs CSV                                      â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Figures:                                            â”‚  â”‚
â”‚  â”‚  â€¢ Renders region as image                          â”‚  â”‚
â”‚  â”‚  â€¢ Optional: VLM for descriptions                   â”‚  â”‚
â”‚  â”‚                                                       â”‚  â”‚
â”‚  â”‚  Text:                                               â”‚  â”‚
â”‚  â”‚  â€¢ Preserves reading order                          â”‚  â”‚
â”‚  â”‚  â€¢ Maintains structure (headers, paragraphs)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OUTPUT LAYER                              â”‚
â”‚                                                             â”‚
â”‚  â€¢ Markdown (text with structure)                          â”‚
â”‚  â€¢ CSV (tables)                                            â”‚
â”‚  â€¢ PNG (figures)                                           â”‚
â”‚  â€¢ JSON (metadata)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Flow (Detailed)

**Example: Processing a research paper**

```
Input: NIPS-2017-attention-is-all-you-need-Paper.pdf
       15 pages, 3 figures, 4 tables

Step 1: PDF Parsing (0.5 seconds)
â”œâ”€ Open PDF with PyPDFium2
â”œâ”€ Render each page at 144 DPI
â”‚  Page 1: 1200x1600 pixels
â”‚  Page 2: 1200x1600 pixels
â”‚  ...
â””â”€ Extract metadata (title, author, etc.)

Step 2: Layout Analysis (4 seconds)
â”œâ”€ Load Layout-Heron model (500MB)
â”œâ”€ Run on each page image
â”‚  Page 1:
â”‚  â”œâ”€ Detected: Title at (100, 50)
â”‚  â”œâ”€ Detected: Abstract at (100, 120)
â”‚  â”œâ”€ Detected: Text block at (100, 300)
â”‚  â””â”€ Detected: Figure at (100, 700)
â”‚
â”‚  Page 5:
â”‚  â”œâ”€ Detected: Section header
â”‚  â”œâ”€ Detected: Table at (100, 400)
â”‚  â””â”€ Detected: Caption below table
â”‚
â””â”€ Build document tree:
   Document
   â”œâ”€ Title: "Attention Is All You Need"
   â”œâ”€ Abstract: {...}
   â”œâ”€ Section: "Introduction"
   â”‚  â””â”€ Paragraphs: [...]
   â”œâ”€ Figure 1
   â”‚  â””â”€ Caption: "The Transformer model architecture"
   â””â”€ Table 1
      â””â”€ Caption: "Model variants"

Step 3: OCR (0 seconds - skipped)
â”œâ”€ Check if pages are scanned
â”‚  All pages have text layer â†’ Skip OCR âœ“
â””â”€ (For scanned pages, would run OCR here)

Step 4: Specialized Processing (1.5 seconds)
â”œâ”€ Tables (0.5 seconds):
â”‚  For each table bounding box:
â”‚  â”œâ”€ Load TableFormer model (300MB)
â”‚  â”œâ”€ Analyze table structure
â”‚  â”‚  Input: Image region of table
â”‚  â”‚  Output: Cell grid with row/column info
â”‚  â”œâ”€ Parse data:
â”‚  â”‚  Row 1: ["Model", "Parameters", "BLEU"]  (header)
â”‚  â”‚  Row 2: ["Base", "65M", "27.3"]         (data)
â”‚  â”‚  Row 3: ["Big", "213M", "28.4"]         (data)
â”‚  â””â”€ Export as CSV
â”‚
â”œâ”€ Figures (0.8 seconds):
â”‚  For each figure bounding box:
â”‚  â”œâ”€ Get page reference
â”‚  â”œâ”€ Render region at 144 DPI
â”‚  â”‚  Region: (100, 700, 500, 1200)
â”‚  â”‚  Output: 400x500 pixel PNG image
â”‚  â””â”€ Save as figure_N.png
â”‚
â””â”€ Text (0.2 seconds):
   â”œâ”€ Follow reading order from layout analysis
   â”œâ”€ Extract text for each element
   â”œâ”€ Preserve structure:
   â”‚  # Title
   â”‚  
   â”‚  ## Abstract
   â”‚  
   â”‚  ## 1 Introduction
   â”‚  
   â”‚  Text paragraph...
   â””â”€ Export as Markdown

Step 5: Output Generation (0.1 seconds)
â”œâ”€ Save text.md (43,818 characters)
â”œâ”€ Save tables/*.csv (4 files)
â”œâ”€ Save figures/*.png (3 files)
â””â”€ Save metadata.json

Total: 6.3 seconds
```

### Key Insight: Two-Phase Approach

**Phase 1: Understanding (AI)**
- What is this element? (title, text, table, figure)
- Where is it on the page?
- What's the reading order?

**Phase 2: Extraction (Specialized)**
- Text: Direct extraction
- Tables: AI parsing (TableFormer)
- Figures: Rendering
- Scanned: OCR

---

## Models & Libraries Behind the Scenes

### Core Dependencies

```
Docling Stack:

docling (main library)
â”œâ”€ docling-core (document data models)
â”œâ”€ docling-ibm-models (Layout-Heron, TableFormer)
â”œâ”€ docling-parse (PDF/DOCX/PPTX parsers)
â””â”€ dependencies:
    â”œâ”€ PyPDFium2 (PDF parsing)
    â”œâ”€ transformers (HuggingFace - AI models)
    â”œâ”€ torch (PyTorch - deep learning)
    â”œâ”€ PIL (Pillow - image processing)
    â””â”€ Various OCR engines
```

### AI Models Used

#### 1. Layout-Heron (Document Layout Understanding)

**Full name:** `docling-project/docling-layout-heron`

**What it is:**
- Vision Transformer (ViT) model
- Trained on millions of document pages
- Understands document structure visually

**Architecture:**
```
Input: Page image (1200x1600 pixels)
       â†“
Patch Embedding
â”œâ”€ Divide image into 16x16 patches
â”œâ”€ Flatten patches to vectors
â””â”€ Add position embeddings
       â†“
Transformer Encoder (12 layers)
â”œâ”€ Multi-head self-attention
â”œâ”€ Feed-forward networks
â””â”€ Layer normalization
       â†“
Detection Head
â”œâ”€ Bounding box prediction
â”œâ”€ Class prediction (text, table, figure, etc.)
â””â”€ Confidence scores
       â†“
Output: Bounding boxes with labels
[
  {"bbox": [100, 50, 600, 100], "type": "title", "confidence": 0.98},
  {"bbox": [100, 450, 700, 650], "type": "table", "confidence": 0.95},
  ...
]
```

**Training data:**
- Academic papers
- Technical reports
- Books
- Presentations
- Total: ~1 million annotated pages

**Performance:**
- Accuracy: >95% on academic papers
- Speed: ~0.2 seconds per page (GPU)
- Model size: ~500 MB

**Similar models:**
- LayoutLM (Microsoft)
- LayoutLMv2, LayoutLMv3
- DIT (Document Image Transformer)

---

#### 2. TableFormer (Table Structure Recognition)

**Full name:** `docling-project/docling-tableformer`

**What it is:**
- Transformer-based table parser
- Understands table cell structure
- Handles complex tables (merged cells, multi-level headers)

**Architecture:**
```
Input: Table region image
       â†“
Image Encoder (CNN)
â”œâ”€ Extract visual features
â”œâ”€ Detect lines, cells
â””â”€ Feature maps
       â†“
Transformer Encoder
â”œâ”€ Encode table structure
â”œâ”€ Understand cell relationships
â””â”€ Identify headers vs data
       â†“
Decoder
â”œâ”€ Row/column prediction
â”œâ”€ Cell boundary detection
â”œâ”€ Spanning cell detection
â””â”€ Header classification
       â†“
Structure Builder
â”œâ”€ Build cell grid
â”œâ”€ Assign data to cells
â””â”€ Handle merged cells
       â†“
Output: Structured table
Model,Parameters,BLEU
Base,65M,27.3
Big,213M,28.4
```

**Training data:**
- PubTables-1M (scientific tables)
- Custom IBM dataset
- Total: ~500,000 annotated tables

**Capabilities:**
- Simple tables (3x3): 98% accuracy
- Complex tables (merged cells): 92% accuracy
- Multi-level headers: Supported
- Spanning cells: Supported

**Model size:** ~300 MB

---

#### 3. OCR Engines (Text from Images)

**Multiple engines available:**

**Option 1: ocrmac (macOS)**
- Provider: Apple Vision Framework
- Built into macOS
- No download needed
- Languages: 100+
- Quality: Excellent for print

**Option 2: Tesseract**
- Provider: Google (open source)
- Most widely used
- Languages: 100+
- Quality: Good

**Option 3: EasyOCR**
- Provider: JaidedAI (open source)
- GPU support
- Languages: 80+
- Quality: Very good

**Option 4: RapidOCR**
- Provider: Community
- Fastest
- Languages: Limited
- Quality: Good

**How OCR works:**
```
Input: Scanned page image (pixels)
       â†“
Preprocessing
â”œâ”€ Grayscale conversion
â”œâ”€ Noise reduction
â”œâ”€ Binarization (black/white)
â””â”€ Skew correction
       â†“
Text Detection
â”œâ”€ Find text regions
â”œâ”€ Detect lines
â””â”€ Segment characters
       â†“
Character Recognition (CNN)
â”œâ”€ Classify each character
â”œâ”€ A, B, C, ... , 0, 1, 2, ...
â””â”€ Confidence scores
       â†“
Post-processing
â”œâ”€ Language model correction
â”œâ”€ Spell check
â””â”€ Word assembly
       â†“
Output: Machine-readable text
"Attention Is All You Need"
```

**Docling's OCR auto-selection:**
```python
if platform == "macOS":
    use_ocrmac()  # Best for Mac
elif gpu_available:
    use_easyocr()  # GPU-accelerated
else:
    use_tesseract()  # Fallback
```

---

### Supporting Libraries

#### PyPDFium2 (PDF Parsing)

**What it is:** Python bindings for PDFium (Google's PDF renderer)

**What it does:**
- Opens PDF files
- Renders pages as images
- Extracts text positioning
- Accesses embedded resources

**Why Docling uses it:**
- Fast and reliable
- Cross-platform
- Low-level PDF access
- Good rendering quality

**Alternatives:**
- PyMuPDF (fitz)
- PyPDF2
- pdfminer.six

---

#### PyTorch (Deep Learning Framework)

**What it is:** Deep learning library for running AI models

**Used for:**
- Loading Layout-Heron model
- Loading TableFormer model
- Running inference (predictions)
- GPU acceleration (CUDA/MPS)

**Size:** ~800 MB (with dependencies)

**Alternatives:**
- TensorFlow
- JAX
- ONNX Runtime

---

#### Transformers (HuggingFace)

**What it is:** Library for transformer models

**Used for:**
- Model loading from HuggingFace Hub
- Tokenization
- Inference pipeline

**Why needed:**
- Layout-Heron is a transformer model
- Standard interface for AI models

---

#### Pillow (Image Processing)

**What it is:** Python Imaging Library

**Used for:**
- Image format conversion
- Resizing
- Saving PNG files
- Image manipulation

**Alternative:** OpenCV

---

## What Can Docling Do?

### Document Formats Supported

```
Input formats:
â”œâ”€ PDF (.pdf)           â­ Primary focus
â”œâ”€ Microsoft Word (.docx)
â”œâ”€ PowerPoint (.pptx)
â”œâ”€ HTML (.html)
â”œâ”€ Images (.png, .jpg, .jpeg, .tif)
â””â”€ Markdown (.md) - limited

Output formats:
â”œâ”€ Markdown (.md)       â­ Main text output
â”œâ”€ CSV (.csv)          â­ Tables
â”œâ”€ PNG (.png)          â­ Figures
â”œâ”€ JSON (.json)        â­ Metadata
â””â”€ DoclingDocument (Python object)
```

### Extraction Capabilities

#### 1. Text Extraction

**What it extracts:**
- All text content
- Preserves document structure
- Maintains reading order
- Identifies headers (H1, H2, H3)

**Example:**
```markdown
# Attention Is All You Need

## Abstract

The dominant sequence transduction models are based on 
complex recurrent or convolutional neural networks...

## 1 Introduction

Recurrent neural networks, long short-term memory and 
gated recurrent neural networks in particular, have been...

### 1.1 Background

The goal of reducing sequential computation also forms...
```

**Quality:**
- Digital PDFs: >98% accuracy
- Scanned PDFs: 90-95% accuracy (with OCR)
- Complex layouts: Maintains correct order

---

#### 2. Table Extraction

**What it extracts:**
- Table structure (rows, columns)
- Cell contents
- Headers vs data
- Merged cells

**Example:**

**PDF contains:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model      â”‚ Parameters â”‚ BLEU     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Base       â”‚ 65M        â”‚ 27.3     â”‚
â”‚ Big        â”‚ 213M       â”‚ 28.4     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Docling outputs (CSV):**
```csv
Model,Parameters,BLEU
Base,65M,27.3
Big,213M,28.4
```

**Handles:**
- Simple tables: 98% accuracy
- Merged cells: Yes
- Multi-level headers: Yes
- Nested tables: Limited
- Tables spanning pages: Yes

**Better than:**
- PyMuPDF: ~40% accuracy
- pdfplumber: ~70% accuracy
- Camelot: ~80% accuracy (simple tables only)

---

#### 3. Figure Extraction

**What it extracts:**
- All visual elements
- Embedded images (JPEG, PNG)
- **Vector graphics** (LaTeX, TikZ, matplotlib) â­

**How it works:**
```
PDF contains vector graphic:
- Not an embedded image
- Drawing commands (paths, shapes)

Traditional tools:
extract_images() â†’ Returns: [] (nothing found) âŒ

Docling:
1. Detect figure region (bounding box)
2. Render that region as image (144 DPI)
3. Save as PNG âœ“

Result: Vector graphic â†’ PNG image
```

**Example figures captured:**
- LaTeX TikZ diagrams
- Matplotlib charts
- Architecture diagrams
- Flowcharts
- Mathematical diagrams

**This is Docling's key advantage over PyMuPDF!**

---

#### 4. Document Structure

**What it preserves:**
- Reading order (even in multi-column layouts)
- Hierarchical structure (sections, subsections)
- Element relationships (captions with figures/tables)
- Page numbers

**Example:**
```
Document
â”œâ”€ Title: "Attention Is All You Need"
â”œâ”€ Authors: [...]
â”œâ”€ Abstract
â”œâ”€ Section 1: "Introduction"
â”‚  â”œâ”€ Paragraph 1
â”‚  â”œâ”€ Paragraph 2
â”‚  â””â”€ Subsection 1.1: "Background"
â”‚     â””â”€ Paragraph
â”œâ”€ Section 2: "Model Architecture"
â”‚  â”œâ”€ Paragraph
â”‚  â”œâ”€ Figure 1
â”‚  â”‚  â””â”€ Caption: "The Transformer model architecture"
â”‚  â””â”€ Paragraph
â””â”€ Section 3: "Experiments"
   â”œâ”€ Table 1
   â”‚  â””â”€ Caption: "Model variants"
   â””â”€ Paragraph
```

---

#### 5. Metadata Extraction

**What it extracts:**
- Title
- Author(s)
- Creation date
- PDF properties
- Page count
- File size

**Example:**
```json
{
  "title": "Attention Is All You Need",
  "author": "Ashish Vaswani et al.",
  "creator": "LaTeX with hyperref package",
  "producer": "pdfTeX-1.40.17",
  "creation_date": "2017-06-12",
  "pages": 15,
  "file_size_mb": 1.93
}
```

---

### Advanced Features

#### 1. OCR for Scanned Documents

**Automatic detection:**
```python
if page_has_text_layer:
    extract_text_directly()
else:
    run_ocr()  # Scanned page
```

**Quality:**
- Printed text: 95-98% accuracy
- Handwriting: 70-85% accuracy (limited support)
- Languages: 100+ supported

---

#### 2. VLM Integration (Optional)

**Vision Language Models for figure descriptions:**

**Built-in options:**
- SmolVLM (256 MB, fast)
- Granite Vision (2 GB, high quality)

**Example:**
```
Input:  figure_1.png (Transformer architecture)

Output: "This diagram shows an encoder-decoder architecture
         with multi-head attention mechanisms. The encoder
         consists of 6 identical layers, each with two
         sub-layers: multi-head self-attention and position-wise
         feed-forward network..."
```

---

#### 3. Batch Processing

**Process multiple documents:**
```python
converter = DocumentConverter()
results = converter.convert_all(["doc1.pdf", "doc2.pdf", "doc3.pdf"])
```

---

#### 4. Custom Pipelines

**Configure extraction:**
```python
options = PdfPipelineOptions()
options.do_ocr = True              # Enable OCR
options.do_table_structure = True  # Parse tables
options.images_scale = 2.0         # 144 DPI images
options.generate_picture_images = True  # Extract figures
```

---

## Introduction to OCR

### What is OCR?

**OCR = Optical Character Recognition**

```
Converts images of text â†’ Machine-readable text
```

**Example:**
```
Input:  Photo of book page (pixels)
        [Image: Scanned text]

Output: "Chapter 1: Introduction
         The quick brown fox jumps..."
```

### How OCR Works (Simplified)

```
Step 1: Image Preprocessing
â”œâ”€ Convert to grayscale
â”œâ”€ Remove noise
â”œâ”€ Increase contrast
â””â”€ Straighten (deskew)

Step 2: Text Detection
â”œâ”€ Find text regions
â”œâ”€ Separate lines
â””â”€ Segment characters

Step 3: Character Recognition
â”œâ”€ For each character image:
â”‚  â”œâ”€ Extract features
â”‚  â”œâ”€ Compare to trained patterns
â”‚  â””â”€ Classify (A, B, C, ... 0, 1, 2...)
â””â”€ Output: Character sequence

Step 4: Post-processing
â”œâ”€ Language model correction
â”‚  "Tke" â†’ "The" (spelling)
â”œâ”€ Dictionary lookup
â””â”€ Context-aware corrections

Output: "The quick brown fox..."
```

### Modern OCR (Deep Learning)

**Old OCR (2000s):**
- Template matching
- Feature extraction
- Rule-based

**Modern OCR (2020s):**
- Convolutional Neural Networks (CNN)
- Recurrent Neural Networks (RNN)
- Transformers
- End-to-end learning

**Example: Tesseract 5**
```
Input image
    â†“
CNN (feature extraction)
    â†“
LSTM (sequence modeling)
    â†“
CTC (alignment)
    â†“
Output text
```

### OCR Accuracy Factors

| Factor | Impact |
|--------|--------|
| **Print quality** | High = 98%, Low = 80% |
| **Font** | Standard = 95%, Decorative = 70% |
| **Language** | English = 98%, Mixed = 85% |
| **Scan quality** | 300 DPI = 95%, 150 DPI = 85% |
| **Skew** | Straight = 95%, Tilted = 80% |
| **Noise** | Clean = 95%, Noisy = 75% |

### OCR in Docling

**When used:**
- Scanned PDFs (no text layer)
- Images (.png, .jpg, .tif)
- Photos of documents

**When NOT used:**
- Digital PDFs (already have text)
- Most modern PDFs

**Engines supported:**
- ocrmac (macOS) - Recommended
- Tesseract (all platforms)
- EasyOCR (GPU support)
- RapidOCR (fastest)

---

## Alternatives to Docling

### Open Source Alternatives

#### 1. PyMuPDF (fitz)

**What it is:** PDF parsing library

**Pros:**
- Very fast (3 seconds vs 6)
- Simple API
- Small footprint (10 MB)
- No authentication needed

**Cons:**
- Basic table extraction (~40% accuracy)
- Can't extract vector graphics
- No AI understanding
- Page-by-page text (no structure)

**When to use:**
- Simple text extraction
- Speed critical
- No complex tables

**Code:**
```python
import fitz
doc = fitz.open("paper.pdf")
text = ""
for page in doc:
    text += page.get_text()
```

---

#### 2. pdfplumber

**What it is:** PDF analysis toolkit

**Pros:**
- Good table extraction (~70% accuracy)
- Layout analysis
- Configurable
- Active development

**Cons:**
- Heuristic-based (not AI)
- No vector graphics
- Complex API

**When to use:**
- Tables important
- Need customization
- No AI models wanted

**Code:**
```python
import pdfplumber
with pdfplumber.open("paper.pdf") as pdf:
    for page in pdf.pages:
        tables = page.extract_tables()
```

---

#### 3. Camelot

**What it is:** Table extraction specialist

**Pros:**
- Excellent for simple tables (~80% accuracy)
- Two methods (lattice, stream)
- Focused tool

**Cons:**
- Tables only (no text/figures)
- Fails on complex tables
- Slow

**When to use:**
- ONLY need tables
- Tables are simple/well-structured

**Code:**
```python
import camelot
tables = camelot.read_pdf("paper.pdf", pages='all')
tables[0].to_csv('output.csv')
```

---

#### 4. Marker

**What it is:** High-quality PDF to Markdown

**Pros:**
- Excellent quality (>95%)
- Great for markdown conversion
- Handles figures

**Cons:**
- Very slow (25 seconds vs 6)
- Complex setup
- Heavy dependencies

**When to use:**
- Highest quality markdown needed
- Don't mind slow processing

---

#### 5. Unstructured

**What it is:** Document processing framework

**Pros:**
- Multi-format support
- Good for pipelines
- Active community

**Cons:**
- Complex API
- Variable quality
- Heavy

**When to use:**
- Building larger system
- Need many formats

---

### Paid/Cloud Alternatives

#### 1. Adobe PDF Services API

**Provider:** Adobe  
**Type:** Cloud API  

**Pros:**
- Excellent quality (best in class)
- Fast (cloud processing)
- Supports all PDF features
- Professional support

**Cons:**
- Expensive ($0.05-0.10 per page)
- Requires internet
- Proprietary

**Pricing:**
- 500 pages/month: Free
- 10,000 pages/month: $50
- 100,000 pages/month: $400

**When to use:**
- Enterprise production
- Budget available
- Highest quality needed

**Code:**
```python
from adobe.pdfservices.operation.auth.credentials import Credentials
credentials = Credentials.service_account_credentials_builder()...
```

---

#### 2. AWS Textract

**Provider:** Amazon Web Services  
**Type:** Cloud OCR + Analysis  

**Pros:**
- Advanced table extraction
- Form extraction
- Handwriting support
- Scalable

**Cons:**
- Costs money
- Requires AWS account
- Internet needed

**Pricing:**
- OCR: $1.50 per 1,000 pages
- Tables: $15 per 1,000 pages
- Forms: $50 per 1,000 pages

**When to use:**
- Already using AWS
- Need form extraction
- Large-scale processing

**Code:**
```python
import boto3
textract = boto3.client('textract')
response = textract.analyze_document(
    Document={'S3Object': {'Bucket': 'my-bucket', 'Name': 'doc.pdf'}},
    FeatureTypes=['TABLES', 'FORMS']
)
```

---

#### 3. Google Document AI

**Provider:** Google Cloud  
**Type:** Cloud document processing  

**Pros:**
- High quality
- Many specialized processors
- Good for invoices/receipts
- GCP integration

**Cons:**
- Expensive
- Complex setup
- Internet required

**Pricing:**
- General processor: $1.50 per 1,000 pages
- Specialized: $30-65 per 1,000 pages

**When to use:**
- Using Google Cloud
- Need specialized extraction
- Enterprise scale

---

#### 4. Microsoft Azure Form Recognizer

**Provider:** Microsoft Azure  
**Type:** Cloud AI for documents  

**Pros:**
- Good for forms/invoices
- Custom model training
- Azure integration

**Cons:**
- Expensive
- Learning curve
- Internet needed

**Pricing:**
- Read (OCR): $1.50 per 1,000 pages
- Layout: $10 per 1,000 pages
- Custom models: $40 per 1,000 pages

---

#### 5. Mathpix

**Provider:** Mathpix  
**Type:** Cloud OCR (math-focused)  

**Pros:**
- Excellent for equations
- LaTeX output
- Good for academic papers

**Cons:**
- Expensive
- Limited to math/technical docs
- Internet required

**Pricing:**
- 1,000 pages/month: $5
- 10,000 pages/month: $50

**When to use:**
- Heavy math content
- Need LaTeX equations
- Academic papers

---

### Comparison Matrix

| Tool | Type | Cost | Tables | Figures | Quality | Speed |
|------|------|------|--------|---------|---------|-------|
| **Docling** | Open | Free | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| PyMuPDF | Open | Free | â­â­ | â­â­ | â­â­â­ | â­â­â­â­â­ |
| pdfplumber | Open | Free | â­â­â­ | â­ | â­â­â­ | â­â­â­â­ |
| Camelot | Open | Free | â­â­â­â­ | N/A | â­â­â­ | â­â­ |
| Marker | Open | Free | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­ |
| Adobe API | Cloud | $$$ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| AWS Textract | Cloud | $$ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| Google Doc AI | Cloud | $$ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| Azure Form | Cloud | $$ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |

---

## Comparison: Open Source vs Paid vs Cloud

### Open Source (Docling, PyMuPDF, etc.)

**Advantages:**
- âœ… Free (no per-page costs)
- âœ… Run locally (data privacy)
- âœ… No internet required
- âœ… Customizable
- âœ… No vendor lock-in

**Disadvantages:**
- âŒ Setup required
- âŒ Need compute resources
- âŒ Model downloads (GB)
- âŒ Slower updates

**Best for:**
- Academic research
- Startups
- Privacy-sensitive data
- Learning/experimentation

---

### Paid Cloud (Adobe, AWS, Google)

**Advantages:**
- âœ… Highest quality
- âœ… No setup
- âœ… Scalable
- âœ… Professional support
- âœ… Always updated

**Disadvantages:**
- âŒ Costs money (per page)
- âŒ Internet required
- âŒ Data sent to cloud
- âŒ Vendor lock-in
- âŒ Rate limits

**Best for:**
- Enterprise production
- Large-scale processing
- Critical applications
- When budget available

---

### Hybrid Approach

**Strategy:**
```
Development â†’ Use Docling (free)
              Test algorithms
              Prototype

Production  â†’ If quality sufficient: Keep Docling
              If need better: Upgrade to cloud
              
Critical docs â†’ Cloud API (Adobe, AWS)
Simple docs  â†’ Docling (free)
```

---

## When to Use What

### Decision Tree

```
Do you need document extraction?
â”œâ”€ Yes â†’ Continue
â””â”€ No â†’ Done!

Is it a PDF?
â”œâ”€ Yes â†’ Continue
â”œâ”€ DOCX/PPTX â†’ Use Docling or python-docx
â””â”€ Image â†’ Use OCR directly

Is it scanned or digital?
â”œâ”€ Scanned â†’ Need OCR
â”‚   â”œâ”€ Use Docling (auto-OCR)
â”‚   â””â”€ Or Tesseract directly
â””â”€ Digital â†’ Continue

What do you need?
â”œâ”€ Just text
â”‚   â”œâ”€ Simple: PyMuPDF
â”‚   â””â”€ Complex layout: Docling
â”‚
â”œâ”€ Tables important
â”‚   â”œâ”€ Simple tables: Camelot
â”‚   â”œâ”€ Complex tables: Docling
â”‚   â””â”€ Best quality: Adobe API
â”‚
â”œâ”€ Figures important
â”‚   â”œâ”€ Embedded only: PyMuPDF
â”‚   â””â”€ Vector graphics: Docling (only option!)
â”‚
â””â”€ Everything (text + tables + figures)
    â”œâ”€ Free: Docling â­
    â”œâ”€ Best quality: Adobe API
    â””â”€ Fast & simple: PyMuPDF (limited)

Budget available?
â”œâ”€ Yes â†’ Consider cloud (Adobe, AWS)
â””â”€ No â†’ Use Docling

Data privacy concern?
â”œâ”€ Yes â†’ Must use local (Docling, PyMuPDF)
â””â”€ No â†’ Cloud OK

Processing scale?
â”œâ”€ 1-100 docs â†’ Any tool works
â”œâ”€ 100-10,000 docs â†’ Docling or cloud
â””â”€ 10,000+ docs â†’ Cloud (scalability)
```

---

### Use Case Matrix

| Use Case | Recommended Tool | Why |
|----------|-----------------|-----|
| **Academic papers** | Docling | Complex layouts, tables, figures |
| **Simple reports** | PyMuPDF | Fast, good enough |
| **Data extraction** | Docling | Best tables |
| **Invoices/forms** | AWS Textract | Specialized |
| **Scanned books** | Docling + OCR | Quality OCR |
| **Learning** | Docling | Free, full-featured |
| **Production** | Docling â†’ Cloud | Start free, upgrade if needed |
| **Math papers** | Mathpix | Equations |
| **Legal docs** | Adobe API | Highest quality |
| **Quick prototype** | PyMuPDF | Fastest setup |

---

## Getting Started

### Learning Path

**Week 1: Basics**
```
Day 1-2: Understand PDFs
- How PDFs work
- PDF structure
- Text vs scanned

Day 3-4: Try PyMuPDF
- Simple extraction
- Understand limitations

Day 5-7: Learn Docling
- Install and setup
- Extract first document
- Understand AI models
```

**Week 2: Advanced**
```
Day 1-3: Deep dive into Docling
- Configure pipelines
- Handle different document types
- Optimize quality

Day 4-5: OCR
- Understand when needed
- Configure OCR engines
- Quality optimization

Day 6-7: Figures and tables
- Master table extraction
- Figure rendering
- VLM descriptions (optional)
```

**Week 3: Production**
```
Day 1-2: Batch processing
- Process multiple docs
- Error handling
- Monitoring

Day 3-4: Optimization
- Speed improvements
- Quality tuning
- Resource management

Day 5-7: Build RAG system
- Chunk documents
- Create embeddings
- Build vector store
```

---

### Installation Quick Start

```bash
# 1. Install Docling
pip install 2_docling huggingface-hub pillow

# 2. Login to HuggingFace
huggingface-cli login
# Get token from: https://huggingface.co/settings/tokens

# 3. Test installation
python -c "from docling.document_converter import DocumentConverter; print('âœ“ Ready!')"

# 4. Extract your first document
python
>>> from 2_docling.document_converter import DocumentConverter
>>> converter = DocumentConverter()
>>> result = converter.convert("your_document.pdf")
>>> print(result.document.export_to_markdown()[:500])
```

---

### First Script

```python
"""
My First Docling Script
Extract text, tables, and figures from PDF
"""

from docling.document_converter import DocumentConverter
from pathlib import Path

# Initialize converter
converter = DocumentConverter()

# Convert PDF
result = converter.convert("paper.pdf")
document = result.document

# Save text
with open("output.md", "w") as f:
    f.write(document.export_to_markdown())
print("âœ“ Text saved to output.md")

# Save tables
for i, table in enumerate(document.tables, 1):
    df = table.to_dataframe()
    df.to_csv(f"table_{i}.csv", index=False)
    print(f"âœ“ Table {i} saved")

# Save figures
from docling_core.types.doc import PictureItem
fig_num = 0
for element, _level in document.iterate_items():
    if isinstance(element, PictureItem):
        fig_num += 1
        image = element.get_image(document)
        if image:
            image.save(f"figure_{fig_num}.png")
            print(f"âœ“ Figure {fig_num} saved")

print(f"\nComplete! Extracted {fig_num} figures and {len(list(document.tables))} tables")
```

---

### Resources

**Official:**
- Documentation: https://docling-project.github.io/docling/
- GitHub: https://github.com/DS4SD/docling
- Examples: https://docling-project.github.io/docling/examples/
- Paper: https://arxiv.org/abs/2408.09869

**Learning:**
- HuggingFace Models: https://huggingface.co/docling-project
- PyTorch Tutorials: https://pytorch.org/tutorials/
- Transformers Docs: https://huggingface.co/docs/transformers

**Community:**
- GitHub Issues: https://github.com/DS4SD/docling/issues
- Discussions: https://github.com/DS4SD/docling/discussions

---

## Summary

### Key Takeaways

1. **Docling = AI-Powered Document Understanding**
   - Not just text extraction
   - Understands structure with AI
   - Handles complex layouts

2. **Three AI Models**
   - Layout-Heron: Document structure (500MB)
   - TableFormer: Table parsing (300MB)
   - OCR: Text from scans (varies)

3. **Unique Advantage: Vector Graphics**
   - Renders LaTeX/TikZ diagrams
   - Only tool that does this well
   - Critical for academic papers

4. **Free & Open Source**
   - No per-page costs
   - Apache 2.0 license
   - Run locally

5. **Production Ready**
   - 6 seconds per document (cached)
   - >95% accuracy
   - Batch processing supported

6. **When to Use Docling**
   - Complex documents âœ…
   - Need tables AND figures âœ…
   - Academic/technical papers âœ…
   - Budget limited âœ…
   - Privacy important âœ…

7. **When to Use Alternatives**
   - Simple extraction â†’ PyMuPDF (faster)
   - Need best quality + have budget â†’ Adobe API
   - Tables only â†’ Camelot

---

## What's Next?

After mastering Docling, you can:

1. **Build RAG Systems**
   - Extract documents
   - Create embeddings
   - Build vector stores
   - Query with LLMs

2. **Document Analysis Pipelines**
   - Batch processing
   - Quality monitoring
   - Error handling
   - Scalability

3. **Custom Solutions**
   - Fine-tune models
   - Custom extraction rules
   - Domain-specific processing

4. **Integration**
   - Web applications
   - Cloud deployment
   - API services
   - Automated workflows

---

**Welcome to the world of intelligent document processing!** ðŸš€

**Course:** Applied Generative AI - Module 4  
**Topic:** Document Extraction for RAG Systems  
**Last Updated:** January 2026
